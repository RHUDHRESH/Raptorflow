#!/bin/bash

# RaptorFlow GCP Deployment Script
set -e

echo "ğŸš€ Deploying RaptorFlow to Google Cloud Platform..."

# Set variables
PROJECT_ID=${PROJECT_ID:-"raptorflow-prod"}
REGION=${REGION:-"us-central1"}
BACKEND_IMAGE="gcr.io/${PROJECT_ID}/raptorflow-backend"

echo "ğŸ“¦ Building and pushing backend image..."
cd backend
docker build -t ${BACKEND_IMAGE}:latest .
docker push ${BACKEND_IMAGE}:latest

echo "ğŸ”§ Applying Terraform infrastructure..."
cd ../terraform
terraform init
terraform apply -auto-approve

echo "ğŸš€ Deploying backend to Cloud Run..."
gcloud run deploy raptorflow-backend \
  --image ${BACKEND_IMAGE}:latest \
  --region ${REGION} \
  --platform managed \
  --allow-unauthenticated \
  --memory 2Gi \
  --cpu 1 \
  --max-instances 10 \
  --set-env-vars \
  SUPABASE_URL=${SUPABASE_URL} \
  SUPABASE_SERVICE_ROLE_KEY=${SUPABASE_SERVICE_ROLE_KEY} \
  GCP_PROJECT_ID=${PROJECT_ID} \
  GCP_REGION=${REGION} \
  REDIS_HOST=$(gcloud redis instances list --format='value(name)' --filter='name:raptorflow-redis')

echo "ğŸ”§ Setting up Cloud Build triggers..."
gcloud builds triggers create raptorflow-backend \
  --repo-name ${GITHUB_REPO} \
  --repo-owner ${GITHUB_OWNER} \
  --branch-name main \
  --build-config cloudbuild.yaml \
  --description "Auto-build and deploy RaptorFlow backend"

echo "ğŸ“Š Creating BigQuery dataset for analytics..."
bq mk --dataset ${PROJECT_ID}:ai_usage
bq mk --table ${PROJECT_ID}:ai_usage.usage_logs \
  --schema user_id:STRING,model:STRING,prompt_length:INTEGER,response_length:INTEGER,timestamp:TIMESTAMP

echo "âœ… Deployment complete!"
echo ""
echo "ğŸŒ Frontend URL: https://raptorflow.in"
echo "ğŸ”§ Backend URL: $(gcloud run services describe raptorflow-backend --region ${REGION} --format='value(status.url)')"
echo "ğŸ’¾ Storage buckets: gsutil ls"
echo "ğŸ”´ Redis instance: $(gcloud redis instances list --format='value(name)')"
echo "ğŸ§  Vertex AI: https://console.cloud.google.com/vertex-ai"
echo "ğŸ“Š BigQuery: https://console.cloud.google.com/bigquery"
