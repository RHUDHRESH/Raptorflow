import operator
from typing import Annotated, Any, Dict, List, Optional, TypedDict

from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import END, START, StateGraph

from agents.moves import (
    MoveGenerator,
    MovePersistence,
    MoveRefiner,
    ProgressTracker,
    ResourceManager,
    SafetyValidator,
    SkillExecutor,
)
from agents.strategists import (
    BrandVoiceAligner,
    CampaignArcDesigner,
    KPIDefiner,
)
from core.config import get_settings
from db import SupabaseSaver, get_pool, save_campaign
from inference import InferenceProvider
from memory.long_term import LongTermMemory
from memory.semantic import SemanticMemory


class MovesCampaignsState(TypedDict):
    """
    SOTA State Schema for Moves & Campaigns Orchestrator.
    Manages the lifecycle from business context to 90-day strategy and weekly moves.
    """

    # Core Context
    tenant_id: str
    workspace_id: Optional[str]

    business_context: List[str]  # Ingested "Gold" context snippets
    context_brief: dict  # Multi-agent analysis results (ICPs, UVPs, etc.)

    # Campaign Strategy (90-Day Arc)
    campaign_id: Optional[str]
    strategy_arc: dict  # The generated 90-day plan
    kpi_targets: dict

    # Weekly Moves (Execution)
    current_moves: List[dict]  # List of moves for the current week
    pending_moves: List[dict]  # Moves awaiting execution or approval
    pending_results: List[dict]  # Results from tool execution (Task 66)

    # Multi-Agent State
    last_agent: str
    messages: Annotated[List[str], operator.add]
    error: Optional[str]
    status: str  # planning, execution, monitoring, complete

    # MLOps & Governance
    quality_score: float
    cost_accumulator: float
    telemetry_events: List[dict]
    evaluation: Dict[str, Any]
    user_feedback: str


# Nodes implementation
async def initialize_orchestrator(state: MovesCampaignsState):
    status = state.get("status")
    if status == "new" or not status:
        return {"status": "planning", "messages": ["Orchestrator initialized."]}
    return {"messages": ["Orchestrator resumed."]}


async def inject_context(state: MovesCampaignsState):
    """RAG Node: Injects relevant business context into the state."""
    tenant_id = state.get("tenant_id")
    if not tenant_id:
        return {"messages": ["WARNING: No tenant_id found for context injection."]}

    memory = SemanticMemory()
    memories = await memory.search(
        tenant_id, query="marketing strategy ICP brand kit", limit=3
    )

    context_snippets = [m["content"] for m in memories]
    return {
        "business_context": context_snippets,
        "messages": [f"Injected {len(context_snippets)} business context snippets."],
    }


async def plan_campaign(state: MovesCampaignsState):
    """SOTA Node: Generates the 90-day campaign strategy using AI reasoning."""
    tenant_id = state.get("tenant_id")
    if not tenant_id:
        return {"messages": ["WARNING: No tenant_id for campaign persistence."]}

    # Trigger the real agentic designer
    llm = InferenceProvider.get_model(model_tier="reasoning")
    designer = CampaignArcDesigner(llm)

    # designer(state) returns {"context_brief": {"campaign_arc": ...}}
    result = await designer(state)
    arc = result["context_brief"]["campaign_arc"]

    campaign_data = {
        "title": arc.get("campaign_title", "90-Day Growth Arc"),
        "objective": state.get("context_brief", {}).get(
            "objective", "Scale B2B SaaS reach"
        ),
        "status": "active",
        "arc_data": arc,
        "kpi_targets": state.get("kpi_targets", {}),
        "audit_data": state.get("context_brief", {}).get("brand_alignment", {}),
    }

    campaign_id_state = state.get("campaign_id")

    campaign_id = await save_campaign(
        tenant_id, campaign_data, campaign_id=campaign_id_state
    )

    return {
        "campaign_id": campaign_id,
        "strategy_arc": arc,
        "status": "monitoring",
        "messages": [f"Campaign strategy generated by AI and persisted: {campaign_id}"],
    }


async def campaign_auditor(state: MovesCampaignsState):
    """SOTA Audit Node: Reflexive check on strategy alignment."""
    llm = InferenceProvider.get_model(model_tier="reasoning")
    agent = BrandVoiceAligner(llm)

    result = await agent(state)
    audit_results = result.get("context_brief", {}).get("brand_alignment", {})

    # Persist audit results
    tenant_id = state.get("tenant_id")
    campaign_id = state.get("campaign_id")
    if tenant_id and campaign_id:
        # Fetch current data to not overwrite arc_data if not in state
        # In a real build, we'd use a more surgical update_campaign_audit method
        campaign_data = {
            "title": state.get("strategy_arc", {}).get(
                "campaign_title", "90-Day Growth Arc"
            ),
            "objective": state.get("context_brief", {}).get(
                "objective", "Scale B2B SaaS reach"
            ),
            "status": "active",
            "arc_data": state.get("strategy_arc", {}),
            "kpi_targets": state.get("kpi_targets", {}),
            "audit_data": audit_results,
        }
        await save_campaign(tenant_id, campaign_data, campaign_id=campaign_id)

    return result


async def approve_campaign(state: MovesCampaignsState):
    """SOTA HITL Node: Awaits human sign-off for the campaign strategy."""
    return {"messages": ["Campaign strategy approved by human."]}


async def generate_moves(state: MovesCampaignsState):
    """SOTA Node: Generates weekly moves from the campaign arc."""
    llm = InferenceProvider.get_model(model_tier="reasoning")
    agent = MoveGenerator(llm)
    return await agent(state)


async def refine_moves(state: MovesCampaignsState):
    """SOTA Node: Refines moves for production readiness."""
    llm = InferenceProvider.get_model(model_tier="driver")
    agent = MoveRefiner(llm)
    return await agent(state)


async def check_resources(state: MovesCampaignsState):
    """SOTA Node: Verifies tool availability."""
    agent = ResourceManager()
    return await agent(state)


async def persist_moves(state: MovesCampaignsState):
    """SOTA Node: Syncs moves to Supabase."""
    agent = MovePersistence()
    return await agent(state)


async def execute_skills(state: MovesCampaignsState):
    """SOTA Node: Executes tools for the current moves."""
    agent = SkillExecutor()
    return await agent(state)


async def validate_safety(state: MovesCampaignsState):
    """SOTA Node: Validates tool outputs."""
    agent = SafetyValidator()
    return await agent(state)


async def track_progress(state: MovesCampaignsState):
    """SOTA Node: Updates campaign progress."""
    agent = ProgressTracker()
    return await agent(state)


async def approve_move(state: MovesCampaignsState):
    """SOTA HITL Node: Awaits human sign-off."""
    return {
        "status": "awaiting_approval",
        "messages": ["Move submitted for human review."],
    }


async def memory_updater(state: MovesCampaignsState):
    """SOTA Memory Node: Syncs results to LongTermMemory."""
    tenant_id = state.get("tenant_id")
    if not tenant_id:
        return {"messages": ["WARNING: No tenant_id for long-term memory sync."]}

    ltm = LongTermMemory()
    await ltm.log_decision(
        tenant_id=tenant_id,
        agent_id=state.get("last_agent", "orchestrator"),
        decision_type="approval_sync",
        input_state={"status": state["status"]},
        rationale=state["messages"][-1] if state["messages"] else "Action completed.",
    )
    return {"messages": ["Long-term audit log updated."]}


async def kpi_setter(state: MovesCampaignsState):
    """SOTA KPI Node: Defines campaign metrics."""
    # Use driver model for metric definition
    llm = InferenceProvider.get_model(model_tier="driver")
    agent = KPIDefiner(llm)
    return await agent(state)


async def handle_error(state: MovesCampaignsState):
    """SOTA Error Handling Node."""
    error_msg = state.get("error") or "Unknown error occurred in cognitive spine."
    return {
        "status": "error",
        "messages": [f"CRITICAL ERROR: {error_msg}"],
        "error": None,  # Reset error after handling
    }


async def evaluate_run(state: MovesCampaignsState):
    """Evaluates telemetry and feedback, persisting learnings post-run."""
    from services.evaluation import EvaluationService

    evaluator = EvaluationService()
    evaluation = evaluator.evaluate_run(
        telemetry_events=state.get("telemetry_events", []),
        output_summary=state.get("strategy_arc")
        or state.get("current_moves")
        or state.get("pending_results"),
        user_feedback=state.get("user_feedback"),
        run_id=state.get("campaign_id"),
        tenant_id=state.get("tenant_id") or state.get("workspace_id"),
    )
    return {"evaluation": evaluation}


def router(state: MovesCampaignsState):
    """SOTA Routing logic for the cognitive spine."""
    if state.get("error"):
        return "error"
    if state["status"] == "planning":
        return "campaign"
    if state["status"] == "monitoring":
        return "moves"
    return END


# Build SOTA Workflow
workflow = StateGraph(MovesCampaignsState)
workflow.add_node("init", initialize_orchestrator)
workflow.add_node("inject_context", inject_context)
workflow.add_node("plan_campaign", plan_campaign)
workflow.add_node("campaign_auditor", campaign_auditor)
workflow.add_node("approve_campaign", approve_campaign)
workflow.add_node("generate_moves", generate_moves)
workflow.add_node("refine_moves", refine_moves)
workflow.add_node("check_resources", check_resources)
workflow.add_node("persist_moves", persist_moves)
workflow.add_node("execute_skills", execute_skills)
workflow.add_node("validate_safety", validate_safety)
workflow.add_node("track_progress", track_progress)
workflow.add_node("approve_move", approve_move)
workflow.add_node("memory_updater", memory_updater)
workflow.add_node("kpi_setter", kpi_setter)
workflow.add_node("evaluate", evaluate_run)
workflow.add_node("error_handler", handle_error)

workflow.add_edge(START, "init")
workflow.add_edge("init", "inject_context")

workflow.add_conditional_edges(
    "inject_context",
    router,
    {
        "campaign": "plan_campaign",
        "moves": "generate_moves",
        "error": "error_handler",
        END: END,
    },
)

workflow.add_edge("plan_campaign", "campaign_auditor")
workflow.add_edge("campaign_auditor", "approve_campaign")
workflow.add_edge("approve_campaign", "memory_updater")

workflow.add_edge("generate_moves", "refine_moves")
workflow.add_edge("refine_moves", "check_resources")
workflow.add_edge("check_resources", "persist_moves")
workflow.add_edge("persist_moves", "execute_skills")
workflow.add_edge("execute_skills", "validate_safety")
workflow.add_edge("validate_safety", "approve_move")
workflow.add_edge("approve_move", "track_progress")
workflow.add_edge("track_progress", "memory_updater")

workflow.add_edge("memory_updater", "kpi_setter")
workflow.add_edge("kpi_setter", "evaluate")
workflow.add_edge("evaluate", END)
workflow.add_edge("error_handler", "evaluate")


# Initialize persistence checkpointer based on environment


def get_checkpointer():
    """Industrial checkpointer for production state management."""
    settings = get_settings()
    db_url = settings.DATABASE_URL
    if db_url and "supabase" in db_url:
        # Production persistence
        pool = get_pool()
        return SupabaseSaver(pool)
    else:
        # Development fallback
        return MemorySaver()


# Compile with persistence and HITL
moves_campaigns_orchestrator = workflow.compile(
    checkpointer=get_checkpointer(),
    interrupt_before=["approve_campaign", "approve_move"],
)
