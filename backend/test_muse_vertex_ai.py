#!/usr/bin/env python3
"""
Test Muse Vertex AI Integration
"""

import os
import asyncio
import sys
import json
from dotenv import load_dotenv

load_dotenv()

# Set the working model
os.environ['VERTEX_AI_MODEL'] = 'gemini-2.0-flash-exp'

# Add current directory to path
sys.path.append('.')

async def main():
    """Main test function"""
    try:
        # Import the Muse Vertex AI service directly
        import api.v1.muse_vertex_ai as muse_api
        
        print("ğŸš€ Testing Muse Vertex AI Integration")
        print("=" * 60)
        
        # Mock the database dependency for testing
        class MockDB:
            async def execute(self, query, *params):
                print(f"ğŸ“Š DB Query: {query[:50]}...")
                return None
        
        class MockUser:
            id = "test-user"
            email = "test@example.com"
        
        # Test content generation
        print("\nğŸ“ Test 1: Content Generation")
        content_request = muse_api.ContentRequest(
            task="Create a compelling blog post introduction about AI-powered marketing automation",
            context={
                "platform": "Raptorflow",
                "industry": "Marketing Technology",
                "target_length": "200-300 words"
            },
            user_id="test-user",
            workspace_id="test-workspace",
            content_type="blog",
            tone="professional",
            target_audience="marketing professionals",
            max_tokens=500
        )
        
        # Test content generation
        content_response = await muse_api.generate_content_with_vertex_ai(
            content_request,
            MockUser(),
            MockDB()
        )
        
        print(f"âœ… Success: {content_response.success}")
        print(f"ğŸ“ Content: {content_response.content[:200]}...")
        print(f"ğŸ“Š Tokens: {content_response.tokens_used}")
        print(f"ğŸ’° Cost: ${content_response.cost_usd:.6f}")
        print(f"â±ï¸  Time: {content_response.generation_time_seconds:.2f}s")
        print(f"ğŸ¤– Model: {content_response.model_used}")
        print(f"ğŸ“ˆ SEO Score: {content_response.seo_score:.2f}")
        print(f"ğŸ’¡ Suggestions: {len(content_response.suggestions)}")
        
        # Test chat functionality
        print("\nğŸ’¬ Test 2: Chat Interaction")
        chat_request = muse_api.ChatRequest(
            message="How can I improve my email marketing campaigns using AI?",
            conversation_history=[
                muse_api.ChatMessage(role="user", content="Hi", timestamp="2024-01-01T10:00:00"),
                muse_api.ChatMessage(role="assistant", content="Hello! I'm here to help with your marketing questions.", timestamp="2024-01-01T10:00:01")
            ],
            context={
                "current_campaigns": ["Welcome series", "Product launch"],
                "industry": "SaaS"
            },
            user_id="test-user",
            workspace_id="test-workspace",
            max_tokens=400
        )
        
        chat_response = await muse_api.chat_with_vertex_ai(
            chat_request,
            MockUser(),
            MockDB()
        )
        
        print(f"âœ… Success: {chat_response.success}")
        print(f"ğŸ’¬ Response: {chat_response.message[:200]}...")
        print(f"ğŸ“Š Tokens: {chat_response.tokens_used}")
        print(f"ğŸ’° Cost: ${chat_response.cost_usd:.6f}")
        print(f"â±ï¸  Time: {chat_response.generation_time_seconds:.2f}s")
        print(f"ğŸ¤– Model: {chat_response.model_used}")
        print(f"ğŸ’¡ Suggestions: {len(chat_response.suggestions)}")
        
        # Test status endpoint
        print("\nğŸ” Test 3: Service Status")
        status_response = await muse_api.get_vertex_ai_status()
        
        print(f"âœ… Status: {status_response['status']}")
        if status_response['status'] == 'available':
            print(f"ğŸ¤– Model: {status_response['model']}")
            print(f"ğŸ“ Project: {status_response['project_id']}")
            print(f"ğŸŒ Location: {status_response['location']}")
            print(f"ğŸ“Š Rate Limits: {status_response['rate_limits']}")
        
        print("\n" + "=" * 60)
        print("ğŸ“Š Test Summary:")
        
        total_cost = content_response.cost_usd + chat_response.cost_usd
        total_tokens = content_response.tokens_used + chat_response.tokens_used
        
        print(f"ğŸ’° Total Cost: ${total_cost:.6f}")
        print(f"ğŸ“Š Total Tokens: {total_tokens}")
        print(f"ğŸ¯ All tests completed successfully!")
        
        print(f"\nğŸš€ Muse Vertex AI Integration is ready!")
        print(f"âœ… Content generation working")
        print(f"âœ… Chat functionality working")
        print(f"âœ… Status monitoring working")
        print(f"âœ… Cost tracking active")
        print(f"âœ… Database integration ready")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
