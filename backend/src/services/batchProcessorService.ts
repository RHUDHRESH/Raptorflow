/**
 * Batch Processor Service - Groups and processes similar requests efficiently
 *
 * Features:
 * - Request queuing and batching
 * - Similarity-based grouping
 * - Parallel batch execution
 * - Cost optimization through deduplication
 * - Configurable batch sizes and timeouts
 */

import { CostAwareRequest, llmService } from './llmService';
import { sqsJobQueue } from './sqsJobQueue';
import { redisMemory } from './redisMemory';
import { responseCache } from './responseCacheService';

export interface BatchConfig {
  maxBatchSize: number;
  maxWaitTimeMs: number; // How long to wait before processing batch
  similarityThreshold: number; // 0-1, how similar requests need to be
  enabled: boolean;
}

export interface BatchRequest extends CostAwareRequest {
  id: string;
  priority: number;
  createdAt: number;
  similarityKey?: string;
}

export interface BatchResult {
  requestId: string;
  result?: any;
  error?: string;
  processingTime: number;
}

export interface BatchStats {
  totalBatchesProcessed: number;
  totalRequestsProcessed: number;
  averageBatchSize: number;
  averageProcessingTime: number;
  deduplicationRate: number; // Percentage of duplicate requests avoided
  costSavings: number;
}

class BatchProcessorService {
  private readonly BATCH_QUEUE_KEY = 'batch_queue';
  private readonly BATCH_CONFIG_KEY = 'batch_config';
  private readonly STATS_KEY = 'batch_stats';

  private config: BatchConfig = {
    maxBatchSize: 5,
    maxWaitTimeMs: 2000, // 2 seconds
    similarityThreshold: 0.8,
    enabled: true
  };

  private stats: BatchStats = {
    totalBatchesProcessed: 0,
    totalRequestsProcessed: 0,
    averageBatchSize: 0,
    averageProcessingTime: 0,
    deduplicationRate: 0,
    costSavings: 0
  };

  private processingTimer?: NodeJS.Timeout;

  constructor() {
    this.loadConfig();
    this.loadStats();
    this.startBatchProcessor();
  }

  /**
   * Add request to batch queue
   */
  async queueRequest(request: CostAwareRequest, priority: number = 1): Promise<string> {
    if (!this.config.enabled) {
      // If batching disabled, process immediately
      return this.processImmediate(request);
    }

    const batchRequest: BatchRequest = {
      ...request,
      id: `batch_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      priority,
      createdAt: Date.now(),
      similarityKey: this.generateSimilarityKey(request)
    };

    // Add to Redis queue
    await this.addToQueue(batchRequest);

    // Check if we should process immediately
    const queueSize = await this.getQueueSize();
    if (queueSize >= this.config.maxBatchSize) {
      await this.processBatch();
    }

    return batchRequest.id;
  }

  /**
   * Process a batch immediately
   */
  private async processImmediate(request: CostAwareRequest): Promise<string> {
    try {
      const result = await llmService.generate(request);
      const requestId = `immediate_${Date.now()}`;

      // Store result for retrieval
      await this.storeBatchResult(requestId, {
        requestId,
        result,
        processingTime: 0
      });

      return requestId;
    } catch (error) {
      console.error('Immediate processing failed:', error);
      throw error;
    }
  }

  /**
   * Get batch result
   */
  async getBatchResult(requestId: string): Promise<BatchResult | null> {
    const key = `batch_result:${requestId}`;
    const cached = await redisMemory.get(key);

    if (cached) {
      return JSON.parse(cached);
    }

    return null;
  }

  /**
   * Process pending batches
   */
  async processBatch(): Promise<void> {
    const startTime = Date.now();

    try {
      const batch = await this.getNextBatch();
      if (batch.length === 0) return;

      console.log(`ðŸ”„ Processing batch of ${batch.length} requests`);

      // Deduplicate similar requests
      const { uniqueRequests, duplicates } = this.deduplicateBatch(batch);

      console.log(`ðŸ“Š Deduplicated: ${batch.length} â†’ ${uniqueRequests.length} unique requests`);

      // Process unique requests
      const results = await llmService.generateBatch(uniqueRequests);

      // Map results back to all requests (including duplicates)
      const allResults = this.mapResultsToRequests(batch, uniqueRequests, results, duplicates);

      // Store results
      for (const result of allResults) {
        await this.storeBatchResult(result.requestId, result);
      }

      // Update stats
      const processingTime = Date.now() - startTime;
      await this.updateStats(batch.length, uniqueRequests.length, processingTime);

      console.log(`âœ… Batch processed: ${batch.length} requests in ${processingTime}ms`);

    } catch (error) {
      console.error('Batch processing failed:', error);
    }
  }

  /**
   * Get batch statistics
   */
  async getStats(): Promise<BatchStats> {
    await this.loadStats();
    return { ...this.stats };
  }

  /**
   * Update batch configuration
   */
  async updateConfig(newConfig: Partial<BatchConfig>): Promise<void> {
    this.config = { ...this.config, ...newConfig };
    await redisMemory.store(this.BATCH_CONFIG_KEY, JSON.stringify(this.config), 86400);
    console.log('Batch config updated:', this.config);
  }

  // ===== PRIVATE METHODS =====

  private async addToQueue(request: BatchRequest): Promise<void> {
    const queueKey = `${this.BATCH_QUEUE_KEY}:${request.priority}`;
    await redisMemory.store(
      `${queueKey}:${request.id}`,
      JSON.stringify(request),
      300 // 5 minutes TTL
    );
  }

  private async getQueueSize(): Promise<number> {
    // Simplified - would need to count keys in production
    // For now, assume queue size checking
    return 0; // TODO: Implement proper queue size checking
  }

  private async getNextBatch(): Promise<BatchRequest[]> {
    const batch: BatchRequest[] = [];
    const maxSize = this.config.maxBatchSize;

    // Get from priority queues (simplified)
    for (let priority = 1; priority <= 5 && batch.length < maxSize; priority++) {
      const queueKey = `${this.BATCH_QUEUE_KEY}:${priority}`;
      // TODO: Implement proper queue retrieval
      // For now, return empty batch
    }

    return batch;
  }

  private generateSimilarityKey(request: CostAwareRequest): string {
    // Generate similarity key based on messages and model
    const messages = request.messages.map(m => m.content.toLowerCase().slice(0, 100)).join(' ');
    const model = request.model || 'default';

    // Simple hash of combined content
    let hash = 0;
    for (let i = 0; i < messages.length; i++) {
      const char = messages.charCodeAt(i);
      hash = ((hash << 5) - hash) + char;
      hash = hash & hash; // Convert to 32-bit integer
    }

    return `${model}_${Math.abs(hash).toString(36)}`;
  }

  private deduplicateBatch(batch: BatchRequest[]): {
    uniqueRequests: CostAwareRequest[];
    duplicates: Map<string, string[]>; // similarityKey -> [requestIds]
  } {
    const uniqueRequests: CostAwareRequest[] = [];
    const duplicates = new Map<string, string[]>();
    const seenKeys = new Set<string>();

    for (const request of batch) {
      const key = request.similarityKey || '';

      if (!seenKeys.has(key)) {
        seenKeys.add(key);
        uniqueRequests.push(request);
        duplicates.set(key, [request.id]);
      } else {
        const existing = duplicates.get(key) || [];
        existing.push(request.id);
        duplicates.set(key, existing);
      }
    }

    return { uniqueRequests, duplicates };
  }

  private mapResultsToRequests(
    originalBatch: BatchRequest[],
    uniqueRequests: CostAwareRequest[],
    results: any[],
    duplicates: Map<string, string[]>
  ): BatchResult[] {
    const allResults: BatchResult[] = [];
    const resultMap = new Map<string, any>();

    // Map unique results
    uniqueRequests.forEach((req, index) => {
      resultMap.set(req.id || `req_${index}`, results[index]);
    });

    // Map all requests including duplicates
    for (const request of originalBatch) {
      const result = resultMap.get(request.id);
      if (result) {
        allResults.push({
          requestId: request.id,
          result,
          processingTime: Date.now() - request.createdAt
        });
      }
    }

    return allResults;
  }

  private async storeBatchResult(requestId: string, result: BatchResult): Promise<void> {
    const key = `batch_result:${requestId}`;
    await redisMemory.store(key, JSON.stringify(result), 3600); // 1 hour TTL
  }

  private async updateStats(
    totalRequests: number,
    uniqueRequests: number,
    processingTime: number
  ): Promise<void> {
    const deduplicationRate = totalRequests > 0 ? (totalRequests - uniqueRequests) / totalRequests : 0;

    this.stats.totalBatchesProcessed++;
    this.stats.totalRequestsProcessed += totalRequests;
    this.stats.averageBatchSize = this.stats.totalRequestsProcessed / this.stats.totalBatchesProcessed;
    this.stats.averageProcessingTime = (
      (this.stats.averageProcessingTime * (this.stats.totalBatchesProcessed - 1)) + processingTime
    ) / this.stats.totalBatchesProcessed;
    this.stats.deduplicationRate = (
      (this.stats.deduplicationRate * (this.stats.totalBatchesProcessed - 1)) + deduplicationRate
    ) / this.stats.totalBatchesProcessed;

    // Estimate cost savings (rough calculation)
    const duplicateSavings = (totalRequests - uniqueRequests) * 0.03; // Assume $0.03 per duplicate avoided
    this.stats.costSavings += duplicateSavings;

    await redisMemory.store(this.STATS_KEY, JSON.stringify(this.stats), 86400);
  }

  private async loadConfig(): Promise<void> {
    try {
      const config = await redisMemory.get(this.BATCH_CONFIG_KEY);
      if (config) {
        this.config = { ...this.config, ...JSON.parse(config) };
      }
    } catch (error) {
      console.warn('Failed to load batch config:', error);
    }
  }

  private async loadStats(): Promise<void> {
    try {
      const stats = await redisMemory.get(this.STATS_KEY);
      if (stats) {
        this.stats = { ...this.stats, ...JSON.parse(stats) };
      }
    } catch (error) {
      console.warn('Failed to load batch stats:', error);
    }
  }

  private startBatchProcessor(): void {
    // Process batches periodically
    this.processingTimer = setInterval(async () => {
      try {
        const queueSize = await this.getQueueSize();
        if (queueSize > 0) {
          await this.processBatch();
        }
      } catch (error) {
        console.error('Batch processor error:', error);
      }
    }, this.config.maxWaitTimeMs);

    console.log('Batch processor started with config:', this.config);
  }

  /**
   * Cleanup method
   */
  async shutdown(): Promise<void> {
    if (this.processingTimer) {
      clearInterval(this.processingTimer);
    }
  }
}

// Export singleton instance
export const batchProcessor = new BatchProcessorService();

// Export types
export type { BatchConfig, BatchRequest, BatchResult, BatchStats };

// Graceful shutdown
process.on('SIGINT', async () => {
  await batchProcessor.shutdown();
});

process.on('SIGTERM', async () => {
  await batchProcessor.shutdown();
});


