#!/bin/bash

# Local testing script for Raptorflow Cloud Scraper
# This script sets up and runs the scraper locally for testing

set -e

echo "ğŸ§ª Setting up local Raptorflow Cloud Scraper..."

# Check if Python is installed
if ! command -v python3 &> /dev/null; then
    echo "âŒ Python 3 is not installed. Please install it first."
    exit 1
fi

# Check if Node.js is installed (for Playwright)
if ! command -v node &> /dev/null; then
    echo "âŒ Node.js is not installed. Please install it first."
    exit 1
fi

# Create virtual environment
echo "ğŸ“¦ Creating virtual environment..."
python3 -m venv venv
source venv/bin/activate

# Install Python dependencies
echo "ğŸ“š Installing Python dependencies..."
pip install --upgrade pip
pip install -r requirements.txt

# Install Playwright browsers
echo "ğŸŒ Installing Playwright browsers..."
npx playwright install chromium

# Set environment variables for local testing
export GOOGLE_CLOUD_PROJECT="raptorflow-481505"
export BUCKET_NAME="raptorflow-scraped-data"
export TOPIC_NAME="scraping-results"
export PORT=8080

echo "âœ… Setup complete!"
echo ""
echo "ğŸš€ Starting local scraper service..."
echo "ğŸŒ Service will be available at: http://localhost:8080"
echo "ğŸ§ª Test with:"
echo "curl -X POST \"http://localhost:8080/scrape\" -H \"Content-Type: application/json\" -d '{\"url\":\"https://www.pepsico.com/en/\",\"user_id\":\"test-user\"}'"
echo ""
echo "ğŸ“Š Health check: curl http://localhost:8080/health"
echo "ğŸ›‘ Stop with: Ctrl+C"
echo ""

# Start the service
python scraper_service.py
