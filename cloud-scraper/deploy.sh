#!/bin/bash

# Raptorflow Cloud Run Scraper Deployment Script
# This script builds and deploys the enhanced scraper to Google Cloud Run

set -e

# Configuration
PROJECT_ID="${GOOGLE_CLOUD_PROJECT:-raptorflow-481505}"
REGION="${REGION:-us-central1}"
SERVICE_NAME="raptorflow-scraper"
BUCKET_NAME="raptorflow-scraped-data"
TOPIC_NAME="scraping-results"

echo "ğŸš€ Deploying Raptorflow Cloud Scraper to Google Cloud Run..."
echo "Project: $PROJECT_ID"
echo "Region: $REGION"
echo "Service: $SERVICE_NAME"

# Check if gcloud is installed
if ! command -v gcloud &> /dev/null; then
    echo "âŒ gcloud CLI is not installed. Please install it first."
    exit 1
fi

# Check if user is logged in
if ! gcloud auth list --filter=status:ACTIVE --format="value(account)" | grep -q "@"; then
    echo "âŒ Please run 'gcloud auth login' first."
    exit 1
fi

# Set the project
echo "ğŸ“‹ Setting project..."
gcloud config set project $PROJECT_ID

# Enable required APIs
echo "ğŸ”§ Enabling required APIs..."
gcloud services enable run.googleapis.com
gcloud services enable cloudbuild.googleapis.com
gcloud services enable storage.googleapis.com
gcloud services enable pubsub.googleapis.com
gcloud services enable logging.googleapis.com

# Create Cloud Storage bucket if it doesn't exist
echo "ğŸ“¦ Creating Cloud Storage bucket..."
if ! gsutil ls gs://$BUCKET_NAME &> /dev/null; then
    gsutil mb gs://$BUCKET_NAME
    echo "âœ… Created bucket: gs://$BUCKET_NAME"
else
    echo "âœ… Bucket already exists: gs://$BUCKET_NAME"
fi

# Create Pub/Sub topic if it doesn't exist
echo "ğŸ“¨ Creating Pub/Sub topic..."
if ! gcloud pubsub topics describe $TOPIC_NAME &> /dev/null; then
    gcloud pubsub topics create $TOPIC_NAME
    echo "âœ… Created topic: $TOPIC_NAME"
else
    echo "âœ… Topic already exists: $TOPIC_NAME"
fi

# Build and deploy the service
echo "ğŸ”¨ Building and deploying Cloud Run service..."
gcloud run deploy $SERVICE_NAME \
    --source . \
    --region $REGION \
    --allow-unauthenticated \
    --port 8080 \
    --min-instances 0 \
    --max-instances 10 \
    --cpu 1 \
    --memory 1Gi \
    --timeout 60s \
    --concurrency 10 \
    --set-env-vars="GOOGLE_CLOUD_PROJECT=$PROJECT_ID" \
    --set-env-vars="BUCKET_NAME=$BUCKET_NAME" \
    --set-env-vars="TOPIC_NAME=$TOPIC_NAME" \
    --set-env-vars="MAX_CONTENT_LENGTH=10000000"

# Get the service URL
SERVICE_URL=$(gcloud run services describe $SERVICE_NAME \
    --region $REGION \
    --format="value(status.url)")

echo "âœ… Deployment complete!"
echo "ğŸŒ Service URL: $SERVICE_URL"
echo "ğŸ§ª Test the service:"
echo "curl -X POST \"$SERVICE_URL/scrape\" -H \"Content-Type: application/json\" -d '{\"url\":\"https://example.com\",\"user_id\":\"test-user\"}'"

# Test the health endpoint
echo "ğŸ¥ Testing health endpoint..."
if curl -s "$SERVICE_URL/health" | grep -q "healthy"; then
    echo "âœ… Health check passed!"
else
    echo "âŒ Health check failed!"
    exit 1
fi

echo "ğŸ‰ Raptorflow Cloud Scraper is ready!"
echo "ğŸ“Š View logs: gcloud logs read \"resource.type=cloud_run_revision\" --limit 50 --format=\"table(textPayload)\""
echo "ğŸ” View service: gcloud run services describe $SERVICE_NAME --region $REGION"
